---
title: "PRUEBA"
format: html
editor: visual
---

## Create Dataset

We will first import the dataset from palmerpenguins library

```{r}
load_all()

df <- palmerpenguins::penguins %>%
  na.omit() %>%
  select(-year) %>%
  filter(species == "Adelie" | species == "Gentoo") %>%
  mutate(species = droplevels(species))
```

We have omitted the ***year*** column and selected only two species (*Adelie* and *Gentoo*) for binary classification.

## Preprocessing Step

We will first preprocess the data set using the **transformer** function. We will pass the dataset along with the formula for our problem. The preprocessing step requires to specify which columns are going to be preprocessed:

-   Numerical columns will be normalized by z-score

-   Categorical columns will be one-hot encoded

In our case, we will preprocess all numerical columns and all categorical columns using the **all** keyword:

```{r}
tidy_object = transformer(df,
                          "species ~ .",
                          norm_num_vars = "all",
                          encode_cat_vars = "all"
                          )
```

The function returns an object with the preprocessing information stored in it. We will need this object for the subsequent steps. e

## Model Definition

In this step will define the model we will use as well as specify the hyperparameters for the model. We will use the **create_models** function. We will pass:

-   tidy_object

-   name of the model we will use (**Random Forest**)

-   Hyperparameter list (this can be ranges to tune or a fixed value)

-   task (**classification**)

```{r}

tidy_object <- create_models(tidy_object,
                             "Random Forest",
                             list(
                                    mtry = c(2,3),
                                    trees = 2
                             ),
                             "classification"
                             )
```

This will again return a **tidy_object** that we will need in the subsequent steps.

## Hyperparameter Tuning

Now we will tune the hyperparameters with the **model_tuning** function. We can use either **Bayesian Optimization** or a grid search with cross validation (**Grid Search CV**). We will also specify the metric we want for model selection, in our case, the area under the receiver operation characteristic curve (**roc_auc**):

```{r}

tidy_object <- model_tuning(tidy_object,
                            tuner = "Grid Search CV", 
                            metrics = "roc_auc"
                            )
```

## Results

Now we can extract the results from our model using the **get_results** function. This function allows to get the performance of our model using a wide variety of metrics as well as using visual plots. In our case we will want:

-   **summary**

-   Receiver Operation Characteristic curve (**roc_curve**)

-   Confusion Matrix (**confusion_matrix**)

-   Calibration curve also known as Reliability plot (**reliability_plot**)

```{r}

results <- get_results(tidy_object,
                       summary = T,
                       roc_curve = T,
                       confusion_matrix = T,
                       reliability_plot = T)
```

## Using the pipe operator (%\>%)

The previous process can be executed in a single "statement" using the **%\>%** operator:

```{r}

results <- transformer(
                          df,
                          "bill_length_mm ~ .",
                          norm_num_vars = "all",
                          encode_cat_vars = "all"
                          ) %>%
  
            create_models( 
                             model_names = "Random Forest",
                             hyperparameters = list(
                                    mtry = c(2,3),
                                    trees = 100
                             ),
                             task = "regression"
                             ) %>%
  
            model_tuning(
                          tuner = "Grid Search CV", 
                          metrics = "rmse"
                            ) %>%
    
            get_results(summary = T,
                        scatter_predictions = T,
                        scatter_residuals = T,
                        residuals_dist = T)

```

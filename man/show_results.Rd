% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/results.R
\name{show_results}
\alias{show_results}
\title{Showcase Summary Results and Plots}
\usage{
show_results(
  analysis_object,
  summary = FALSE,
  roc_curve = FALSE,
  pr_curve = FALSE,
  gain_curve = FALSE,
  lift_curve = FALSE,
  dist_by_class = FALSE,
  reliability_plot = FALSE,
  confusion_matrix = FALSE,
  scatter_residuals = FALSE,
  scatter_predictions = FALSE,
  residuals_dist = FALSE,
  new_data = "test"
)
}
\arguments{
\item{analysis_object}{analysis_object created from fine_tuning function.}

\item{summary}{Whether to plot summary results table. Boolean (FALSE by default).}

\item{roc_curve}{Whether to plot ROC Curve (Classification task only). Boolean (FALSE by default).}

\item{pr_curve}{Whether to plot ROC Curve (Classification task only). Boolean (FALSE by default).}

\item{gain_curve}{Whether to plot ROC Curve (Classification task only). Boolean (FALSE by default).}

\item{lift_curve}{Whether to plot ROC Curve (Classification task only). Boolean (FALSE by default).}

\item{dist_by_class}{Whether to plot distribution of output probability by class (Classification task only).
Boolean (FALSE by default).}

\item{reliability_plot}{Whether to plot Reliability Plot (Binary Classification task only). Boolean (FALSE by default).}

\item{confusion_matrix}{Whether to Confusion Matrix (Classification task only). Boolean (FALSE by default).}

\item{scatter_residuals}{Whether to plot Residuals vs Predictions (Regression task only). Boolean (FALSE by default).}

\item{scatter_predictions}{Whether to plot Predictions vs Observed (Regression task only). Boolean (FALSE by default).}

\item{residuals_dist}{Whether to plot Residuals Distribution (Regression task only). Boolean (FALSE by default).}

\item{new_data}{Data to be used for Confusion Matrix, Reliability Plot, Distribution by Class Plot,
Residuals vs Predictions Plot, Predictions vs Observed Plot and Residuals Distribution Plot.
A string with the name of the data_set: "train", "validation", "test" (default) or "all".}
}
\value{
An updated analysis_object containing the generated predictions, summary statistics, and any
visualizations or diagnostic outputs selected by the user. This object reflects the results of model
evaluation and can be further used for reporting, interpretation, or additional analyses within the
ML tidyML workflow.
}
\description{
The \strong{show_results()} function is a central component of the ML workflow established by the package,
following the stages of data preprocessing, model construction (build_model), and hyperparameter optimization
(fine_tuning). After a model has been trained and tuned, show_results() enables users to generate comprehensive
\strong{visualizations and summaries of model performance}, including metrics tables, ROC and PR curves, gain and lift
curves, confusion matrices, calibration plots, and regression diagnostics, tailored to both regression and
classification tasks. This function provides a thorough and interpretable assessment of the fitted model,
supporting informed evaluation and communication of results. Importantly, show_results() is not the final step
of the workflow, as further analyses such as sensitivity analysis can be performed subsequently to deepen the
understanding of model robustness and behavior (Molnar, 2025).
}
\examples{
# Example 1: Classification Task
# Display summary metrics, ROC curve, and confusion matrix for a classification model with test partition

library(TidyML)

data(sim_data) # sim_data is a simulated dataset wtih psychological variables

tidy_object <- preprocessing(
                             df = sim_data,
                             formula = psych_well_bin ~ depression + emot_intel + resilience + life_sat,
                             task = "classification"
                             )

tidy_object <- build_model(
               analysis_object = tidy_object,
               model_name = "SVM",
               hyperparameters = list(
                                 type = "rbf",
                                 cost = 1,
                                 margin = 0.1,
                                 rbf_sigma = 0.05
                                 )
                           )

tidy_object <- fine_tuning(tidy_object,
                             tuner = "Grid Search CV",
                             metrics = c("roc_auc", "f_meas"),
                             plot_results = TRUE
                             )

tidy_object<-show_results(tidy_object,
                          summary = TRUE,
                          roc_curve = TRUE,
                          confusion_matrix = TRUE,
                          new_data = "test")

# Example 2: Regression Task
# Display summary metrics, scatter plot of predictions, and residuals distribution for a regression model
# with train partition

data(sim_data) # sim_data is a simulated dataset wtih psychological variables

tidy_object <- preprocessing(
                             df = sim_data,
                             formula = psych_well ~ depression + emot_intel + resilience + life_sat,
                             task = "regression"
                             )

tidy_object <- build_model(
               analysis_object = tidy_object,
               model_name = "Neural Network",
               hyperparameters = list(
                                 hidden_units = 10,
                                 activation = "relu",
                                 learn_rate = 0.01
                                 )
                           )

tidy_object <- fine_tuning(tidy_object,
                             tuner = "Bayesian Optimization",
                             metrics = c("rmse", "mape"),
                             plot_results = TRUE
                             )

tidy_object<-show_results(tidy_object,
                          summary = TRUE,
                          scatter_predictions = TRUE,
                          residuals_dist = TRUE,
                          new_data = "train")
}
\references{
Molnar, C. (2025). \emph{Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (3rd. ed.)}.
cristophm.github.io/interpretable-ml-book/
}
